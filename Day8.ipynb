{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e650189-8fbd-4b6d-9fa6-88997547f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "['\\nGensim is an open-source library for topic modeling, document indexing, and other natural language processing (NLP) tasks.', 'It was created by Radim Řehůřek in 2009 and is written in Python.', 'The primary purpose of Gensim is to handle large text corpora using streaming and incremental algorithms.', 'This means Gensim allows us to work with datasets that do not fit entirely in memory.']\n",
      "\n",
      "Tokenized Words:\n",
      "['Gensim', 'is', 'an', 'open-source', 'library', 'for', 'topic', 'modeling', ',', 'document', 'indexing', ',', 'and', 'other', 'natural', 'language', 'processing', '(', 'NLP', ')', 'tasks', '.', 'It', 'was', 'created', 'by', 'Radim', 'Řehůřek', 'in', '2009', 'and', 'is', 'written', 'in', 'Python', '.', 'The', 'primary', 'purpose', 'of', 'Gensim', 'is', 'to', 'handle', 'large', 'text', 'corpora', 'using', 'streaming', 'and', 'incremental', 'algorithms', '.', 'This', 'means', 'Gensim', 'allows', 'us', 'to', 'work', 'with', 'datasets', 'that', 'do', 'not', 'fit', 'entirely', 'in', 'memory', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/haarika/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "paragraph = \"\"\"\n",
    "Gensim is an open-source library for topic modeling, document indexing, and other natural language processing (NLP) tasks.\n",
    "It was created by Radim Řehůřek in 2009 and is written in Python.\n",
    "The primary purpose of Gensim is to handle large text corpora using streaming and incremental algorithms.\n",
    "This means Gensim allows us to work with datasets that do not fit entirely in memory.\n",
    "\"\"\"\n",
    "sentences = sent_tokenize(paragraph)\n",
    "words = word_tokenize(paragraph)\n",
    "print(\"Tokenized Sentences:\")\n",
    "print(sentences)\n",
    "print(\"\\nTokenized Words:\")\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
